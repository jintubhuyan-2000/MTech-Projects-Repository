{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1ca2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import ee\n",
    "from Py6S import *\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "import geemap\n",
    "import ee\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3509ef36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=U0GTMcIuBrxaFiev5BqxyoCLIsGKs6wY4ERvmJVsGEg&tc=ttzVI2Zya0tiX3iX_Wt_6ZdqeIqv7LA0o91nfG4GZhE&cc=rQWgU7x_d1XdXwhfqwcmTdrBf6AZ6CVNLhK59uUz8mE>https://code.earthengine.google.com/client-auth?scopes=https%3A//www.googleapis.com/auth/earthengine%20https%3A//www.googleapis.com/auth/devstorage.full_control&request_id=U0GTMcIuBrxaFiev5BqxyoCLIsGKs6wY4ERvmJVsGEg&tc=ttzVI2Zya0tiX3iX_Wt_6ZdqeIqv7LA0o91nfG4GZhE&cc=rQWgU7x_d1XdXwhfqwcmTdrBf6AZ6CVNLhK59uUz8mE</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you should paste in the box below.</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 4/1AfJohXmsXnGRdlHAyEozIP3paxspTYRWwVMX9uGNcXG54s_fFPU1raQUDRs\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f32004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geemap\n",
    "import ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9950bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e484feb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating URL ...\n",
      "An error occurred while downloading.\n",
      "Total request size (1068253410 bytes) must be less than or equal to 50331648 bytes.\n",
      "Generating URL ...\n",
      "An error occurred while downloading.\n",
      "Total request size (1068253410 bytes) must be less than or equal to 50331648 bytes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geemap\n",
    "import ee\n",
    "\n",
    "def export_landsat_images(start_year, end_year, feature_collection, output_dir, cloudCover):\n",
    "    ee.Initialize()\n",
    "\n",
    "    # Define the region of interest\n",
    "    jharkhand = feature_collection\n",
    "\n",
    "    # Loop through the years\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        images_found = False  # Flag to check if images are found for the current year\n",
    "\n",
    "        # Create a band mapping dictionary based on the Landsat sensor\n",
    "        band_mapping = {\n",
    "            'LT05': {'BLUE': 'B1', 'RED': 'B3', 'NIR': 'B4', 'SWIR': 'B5'},\n",
    "            'LE07': {'BLUE': 'B1', 'RED': 'B3', 'NIR': 'B4', 'SWIR': 'B5'},\n",
    "            'LC08': {'BLUE': 'B2', 'RED': 'B4', 'NIR': 'B5', 'SWIR': 'B6'},\n",
    "            'LC09': {'BLUE': 'B2', 'RED': 'B4', 'NIR': 'B5', 'SWIR': 'B6'}\n",
    "        }\n",
    "\n",
    "        # Get the Landsat sensor based on the year\n",
    "        landsat_sensor = None\n",
    "        if year < 1999:\n",
    "            landsat_sensor = 'LT05'\n",
    "        elif 1999 <= year < 2014:\n",
    "            landsat_sensor = 'LE07'\n",
    "        elif 2014 <= year < 2022:\n",
    "            landsat_sensor = 'LC08'\n",
    "        else:\n",
    "            landsat_sensor = 'LC09'\n",
    "\n",
    "        # Start with an empty image collection for the current year\n",
    "        images = ee.ImageCollection([])\n",
    "\n",
    "        # Iterate through months from January to December\n",
    "        for month in range(1, 13):\n",
    "            # Calculate the month to use, considering wrapping from December to January\n",
    "            current_month = month if month <= 12 else month - 12\n",
    "            current_year = year if month <= 12 else year + 1\n",
    "\n",
    "            # Set the start and end dates for the current month\n",
    "            start_date = f'{current_year}-{current_month:02d}-01'\n",
    "            end_date = f'{current_year}-{current_month:02d}-28'\n",
    "\n",
    "            # Filter Landsat collection for the specified year and month\n",
    "            landsat_collection = ee.ImageCollection(f\"LANDSAT/{landsat_sensor}/C02/T1_TOA\")\n",
    "\n",
    "            images = images.merge(\n",
    "                landsat_collection.filter(ee.Filter.lt('CLOUD_COVER', cloudCover))\n",
    "                .filter(ee.Filter.date(start_date, end_date))\n",
    "                .filterBounds(jharkhand)\n",
    "            )\n",
    "\n",
    "            # Check if images are found for the current month\n",
    "            if images.size().getInfo() > 0:\n",
    "                # Take the mean of the images for the specified period\n",
    "                image = images.mean()\n",
    "\n",
    "                # Check if the image extent covers the full extent of the region\n",
    "                if image.geometry().contains(jharkhand):\n",
    "                    images_found = True\n",
    "\n",
    "                    # Define output filename for Landsat\n",
    "                    landsat_filename = f'Landsat_{year}_{month:02d}.tif'\n",
    "                    landsat_output_dir = \"D:/Jintu/Jintu_ShareFolder/TestDL_2/Landsat Images/Bands/\"\n",
    "                    os.makedirs(landsat_output_dir, exist_ok=True)\n",
    "                    landsat_output_path = os.path.join(landsat_output_dir, landsat_filename)\n",
    "                    geemap.ee_export_image(image, landsat_output_path, region=jharkhand, scale=30, file_per_band=True)\n",
    "\n",
    "                    # Calculate NDVI, EVI, and NDWI\n",
    "                    band_info = band_mapping[landsat_sensor]\n",
    "                    ndvi = image.normalizedDifference([band_info['NIR'], band_info['RED']])\n",
    "                    evi = image.expression(\n",
    "                        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
    "                            'NIR': image.select(band_info['NIR']),\n",
    "                            'RED': image.select(band_info['RED']),\n",
    "                            'BLUE': image.select(band_info['BLUE'])\n",
    "                        })\n",
    "                    ndwi = image.normalizedDifference([band_info['NIR'], band_info['SWIR']])\n",
    "\n",
    "#                     # Define output filenames for NDVI, EVI, and NDWI\n",
    "#                     ndvi_filename = f'Landsat_{year}_{month:02d}_NDVI.tif'\n",
    "#                     evi_filename = f'Landsat_{year}_{month:02d}_EVI.tif'\n",
    "#                     ndwi_filename = f'Landsat_{year}_{month:02d}_NDWI.tif'\n",
    "\n",
    "#                     ndvi_output_dir =  \"D:/Jintu/Jintu_ShareFolder/TestDL_2/Landsat Images/NDVI/\"\n",
    "#                     evi_output_dir =  \"D:/Jintu/Jintu_ShareFolder/TestDL_2/Landsat Images/EVI/\"\n",
    "#                     ndwi_output_dir =  \"D:/Jintu/Jintu_ShareFolder/TestDL_2/Landsat Images/NDWI/\"\n",
    "\n",
    "#                     os.makedirs(ndvi_output_dir, exist_ok=True)\n",
    "#                     os.makedirs(evi_output_dir, exist_ok=True)\n",
    "#                     os.makedirs(ndwi_output_dir, exist_ok=True)\n",
    "\n",
    "#                     # Export NDVI, EVI, and NDWI to separate folders\n",
    "#                     ndvi_output_path = os.path.join(ndvi_output_dir, ndvi_filename)\n",
    "#                     evi_output_path = os.path.join(evi_output_dir, evi_filename)\n",
    "#                     ndwi_output_path = os.path.join(ndwi_output_dir, ndwi_filename)\n",
    "\n",
    "#                     geemap.ee_export_image(ndvi, ndvi_output_path, region=jharkhand, scale=30)\n",
    "#                     geemap.ee_export_image(evi, evi_output_path, region=jharkhand, scale=30)\n",
    "#                     geemap.ee_export_image(ndwi, ndwi_output_path, region=jharkhand, scale=30)\n",
    "\n",
    "                    break  # Exit the loop when an image is found for the current year and month\n",
    "\n",
    "        if not images_found:\n",
    "            # If no images are found for the current year, continue to the next year\n",
    "            print(f\"No images found for year {year}. Moving to the next year.\")\n",
    "\n",
    "# Example usage:\n",
    "start_year = 2021\n",
    "end_year = 2022\n",
    "feature_collection = ee.FeatureCollection(\"projects/webapp-385310/assets/Sonitpur-Udalguri\").geometry()\n",
    "output_dir = '/path/to/output/directory'\n",
    "cloudCover = 30\n",
    "\n",
    "# Export Landsat images, NDVI, EVI, and NDWI for each year, adding months gradually until a suitable image is found\n",
    "export_landsat_images(start_year, end_year, feature_collection, output_dir, cloudCover)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fb7260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02551faa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "187d332e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No images found for year 1984. Moving to the next year.\n",
      "No images found for year 1985. Moving to the next year.\n",
      "No images found for year 1986. Moving to the next year.\n",
      "No images found for year 1987. Moving to the next year.\n",
      "Generating URL ...\n",
      "An error occurred while downloading.\n",
      "Total request size (877831920 bytes) must be less than or equal to 50331648 bytes.\n",
      "Generating URL ...\n",
      "An error occurred while downloading.\n",
      "Total request size (443584560 bytes) must be less than or equal to 50331648 bytes.\n",
      "Generating URL ...\n",
      "An error occurred while downloading.\n",
      "Total request size (88769520 bytes) must be less than or equal to 50331648 bytes.\n",
      "Generating URL ...\n",
      "An error occurred while downloading.\n",
      "Total request size (443584560 bytes) must be less than or equal to 50331648 bytes.\n",
      "Generating URL ...\n",
      "An error occurred while downloading.\n",
      "Total request size (877831920 bytes) must be less than or equal to 50331648 bytes.\n",
      "Generating URL ...\n",
      "An error occurred while downloading.\n",
      "Total request size (443584560 bytes) must be less than or equal to 50331648 bytes.\n",
      "Generating URL ...\n",
      "An error occurred while downloading.\n",
      "Total request size (88769520 bytes) must be less than or equal to 50331648 bytes.\n",
      "Generating URL ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 126\u001b[0m\n\u001b[0;32m    123\u001b[0m cloudCover \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Export Landsat images, NDVI, EVI, and NDWI for each year, adding months gradually until a suitable image is found\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[43mexport_landsat_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_year\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_collection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcloudCover\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[62], line 110\u001b[0m, in \u001b[0;36mexport_landsat_images\u001b[1;34m(start_year, end_year, feature_collection, output_dir, cloudCover)\u001b[0m\n\u001b[0;32m    108\u001b[0m             geemap\u001b[38;5;241m.\u001b[39mee_export_image(ndvi, ndvi_output_path, region\u001b[38;5;241m=\u001b[39mjharkhand, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexport_options)\n\u001b[0;32m    109\u001b[0m             geemap\u001b[38;5;241m.\u001b[39mee_export_image(evi, evi_output_path, region\u001b[38;5;241m=\u001b[39mjharkhand, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexport_options)\n\u001b[1;32m--> 110\u001b[0m             \u001b[43mgeemap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mee_export_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mndwi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndwi_output_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjharkhand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mexport_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Exit the loop when an image is found for the current year and month\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m images_found:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;66;03m# If no images are found for the current year, continue to the next year\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\geemap\\common.py:203\u001b[0m, in \u001b[0;36mee_export_image\u001b[1;34m(ee_object, filename, scale, crs, crs_transform, region, dimensions, file_per_band, format, unzip, unmask_value, timeout, proxies)\u001b[0m\n\u001b[0;32m    200\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mformat\u001b[39m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 203\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[43mee_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetDownloadURL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while downloading.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\ee\\image.py:474\u001b[0m, in \u001b[0;36mImage.getDownloadURL\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    472\u001b[0m request \u001b[38;5;241m=\u001b[39m params \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m    473\u001b[0m request[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m--> 474\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\u001b[38;5;241m.\u001b[39mmakeDownloadUrl(\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetDownloadId\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\ee\\data.py:1219\u001b[0m, in \u001b[0;36mgetDownloadId\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m   1214\u001b[0m queryParams \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfields\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1216\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m: request,\n\u001b[0;32m   1217\u001b[0m }\n\u001b[0;32m   1218\u001b[0m _maybe_populate_workload_tag(queryParams)\n\u001b[1;32m-> 1219\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_cloud_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_cloud_projects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthumbnails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_get_projects_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mqueryParams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocid\u001b[39m\u001b[38;5;124m'\u001b[39m: result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m}\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\ee\\data.py:352\u001b[0m, in \u001b[0;36m_execute_cloud_call\u001b[1;34m(call, num_retries)\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes a Cloud API call and translates errors to EEExceptions.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m  EEException if the call fails.\u001b[39;00m\n\u001b[0;32m    350\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_retries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m googleapiclient\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mHttpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    354\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m _translate_cloud_exception(e)\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\googleapiclient\\_helpers.py:130\u001b[0m, in \u001b[0;36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m positional_parameters_enforcement \u001b[38;5;241m==\u001b[39m POSITIONAL_WARNING:\n\u001b[0;32m    129\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(message)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\googleapiclient\\http.py:923\u001b[0m, in \u001b[0;36mHttpRequest.execute\u001b[1;34m(self, http, num_retries)\u001b[0m\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody))\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# Handle retries for server-side errors.\u001b[39;00m\n\u001b[1;32m--> 923\u001b[0m resp, content \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrequest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_callbacks:\n\u001b[0;32m    936\u001b[0m     callback(resp)\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\googleapiclient\\http.py:191\u001b[0m, in \u001b[0;36m_retry_request\u001b[1;34m(http, num_retries, req_type, sleep, rand, uri, method, *args, **kwargs)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 191\u001b[0m     resp, content \u001b[38;5;241m=\u001b[39m \u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# Retry on SSL errors and socket timeout errors.\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ssl_SSLError \u001b[38;5;28;01mas\u001b[39;00m ssl_error:\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\google_auth_httplib2.py:218\u001b[0m, in \u001b[0;36mAuthorizedHttp.request\u001b[1;34m(self, uri, method, body, headers, redirections, connection_type, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m     body_stream_position \u001b[38;5;241m=\u001b[39m body\u001b[38;5;241m.\u001b[39mtell()\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Make the request.\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m response, content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mredirections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mredirections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# If the response indicated that the credentials needed to be\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# refreshed, then refresh the credentials and re-attempt the\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# request.\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# A stored token may expire between the time it is retrieved and\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;66;03m# the time the request is made, so we may need to try twice.\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    234\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_refresh_status_codes\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m _credential_refresh_attempt \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_refresh_attempts\n\u001b[0;32m    236\u001b[0m ):\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\ee\\_cloud_api_utils.py:62\u001b[0m, in \u001b[0;36m_Http.request\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m     61\u001b[0m   session\u001b[38;5;241m.\u001b[39mmax_redirects \u001b[38;5;241m=\u001b[39m redirections\n\u001b[1;32m---> 62\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m   headers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(response\u001b[38;5;241m.\u001b[39mheaders)\n\u001b[0;32m     65\u001b[0m   headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m             \u001b[43msix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\site-packages\\urllib3\\connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m         \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\ssl.py:1311\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1308\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1309\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1310\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32m~\\.conda\\envs\\TestDL\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geemap\n",
    "import ee\n",
    "\n",
    "def export_landsat_images(start_year, end_year, feature_collection, output_dir, cloudCover):\n",
    "    ee.Initialize()\n",
    "\n",
    "    # Define the region of interest\n",
    "    jharkhand = feature_collection\n",
    "\n",
    "    # Loop through the years\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        images_found = False  # Flag to check if images are found for the current year\n",
    "\n",
    "        # Create a band mapping dictionary based on the Landsat sensor\n",
    "        band_mapping = {\n",
    "            'LT05': {'BLUE': 'B1', 'RED': 'B3', 'NIR': 'B4', 'SWIR': 'B5'},\n",
    "            'LE07': {'BLUE': 'B1', 'RED': 'B3', 'NIR': 'B4', 'SWIR': 'B5'},\n",
    "            'LC08': {'BLUE': 'B2', 'RED': 'B4', 'NIR': 'B5', 'SWIR': 'B6'},\n",
    "            'LC09': {'BLUE': 'B2', 'RED': 'B4', 'NIR': 'B5', 'SWIR': 'B6'}\n",
    "        }\n",
    "\n",
    "        # Get the Landsat sensor based on the year\n",
    "        landsat_sensor = None\n",
    "        if year < 1999:\n",
    "            landsat_sensor = 'LT05'\n",
    "        elif 1999 <= year < 2014:\n",
    "            landsat_sensor = 'LE07'\n",
    "        elif 2014 <= year < 2022:\n",
    "            landsat_sensor = 'LC08'\n",
    "        else:\n",
    "            landsat_sensor = 'LC09'\n",
    "\n",
    "        # Start with an empty image collection for the current year\n",
    "        images = ee.ImageCollection([])\n",
    "\n",
    "        # Iterate through months from January to December\n",
    "        for month in range(1, 13):\n",
    "            # Calculate the month to use, considering wrapping from December to January\n",
    "            current_month = month if month <= 12 else month - 12\n",
    "            current_year = year if month <= 12 else year + 1\n",
    "\n",
    "            # Set the start and end dates for the current month\n",
    "            start_date = f'{current_year}-{current_month:02d}-01'\n",
    "            end_date = f'{current_year}-{current_month:02d}-28'\n",
    "\n",
    "            # Filter Landsat collection for the specified year and month\n",
    "            landsat_collection = ee.ImageCollection(f\"LANDSAT/{landsat_sensor}/C02/T1_TOA\")\n",
    "\n",
    "            images = images.merge(\n",
    "                landsat_collection.filter(ee.Filter.lt('CLOUD_COVER', cloudCover))\n",
    "                .filter(ee.Filter.date(start_date, end_date))\n",
    "                .filterBounds(jharkhand)\n",
    "            )\n",
    "\n",
    "            # Check if images are found for the current month\n",
    "            if images.size().getInfo() > 0:\n",
    "                # Take the mean of the images for the specified period\n",
    "                image = images.mean()\n",
    "\n",
    "                # Check if the image extent covers the full extent of the region\n",
    "                if image.geometry().contains(jharkhand):\n",
    "                    images_found = True\n",
    "\n",
    "                    # Define output filename for Landsat\n",
    "                    landsat_filename = f'Landsat_{year}_{month:02d}.tif'\n",
    "                    landsat_output_dir = \"D:/Jintu/Jintu_ShareFolder/TestDL_2/Landsat Images/Bands/\"\n",
    "                    os.makedirs(landsat_output_dir, exist_ok=True)\n",
    "                    landsat_output_path = os.path.join(landsat_output_dir, landsat_filename)\n",
    "\n",
    "                    # Set CRS and maxPixels parameters\n",
    "                    export_options = {\n",
    "                        'crs': 'EPSG:32644',  # Change to your desired CRS\n",
    "                    }\n",
    "\n",
    "                    # Export the image with export options\n",
    "                    geemap.ee_export_image(image, landsat_output_path, region=jharkhand, scale=30, file_per_band=False, **export_options)\n",
    "\n",
    "                    # Calculate NDVI, EVI, and NDWI\n",
    "                    band_info = band_mapping[landsat_sensor]\n",
    "                    ndvi = image.normalizedDifference([band_info['NIR'], band_info['RED']])\n",
    "                    evi = image.expression(\n",
    "                        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
    "                            'NIR': image.select(band_info['NIR']),\n",
    "                            'RED': image.select(band_info['RED']),\n",
    "                            'BLUE': image.select(band_info['BLUE'])\n",
    "                        })\n",
    "                    ndwi = image.normalizedDifference([band_info['NIR'], band_info['SWIR']])\n",
    "\n",
    "                    # Define output filenames for NDVI, EVI, and NDWI\n",
    "                    ndvi_filename = f'Landsat_{year}_{month:02d}_NDVI.tif'\n",
    "                    evi_filename = f'Landsat_{year}_{month:02d}_EVI.tif'\n",
    "                    ndwi_filename = f'Landsat_{year}_{month:02d}_NDWI.tif'\n",
    "\n",
    "                    ndvi_output_dir =  \"D:/Jintu/Jintu_ShareFolder/TestDL_2/Landsat Images/NDVI/\"\n",
    "                    evi_output_dir =  \"D:/Jintu/Jintu_ShareFolder/TestDL_2/Landsat Images/EVI/\"\n",
    "                    ndwi_output_dir =  \"D:/Jintu/Jintu_ShareFolder/TestDL_2/Landsat Images/NDWI/\"\n",
    "\n",
    "                    os.makedirs(ndvi_output_dir, exist_ok=True)\n",
    "                    os.makedirs(evi_output_dir, exist_ok=True)\n",
    "                    os.makedirs(ndwi_output_dir, exist_ok=True)\n",
    "\n",
    "                    # Export NDVI, EVI, and NDWI to separate folders\n",
    "                    ndvi_output_path = os.path.join(ndvi_output_dir, ndvi_filename)\n",
    "                    evi_output_path = os.path.join(evi_output_dir, evi_filename)\n",
    "                    ndwi_output_path = os.path.join(ndwi_output_dir, ndwi_filename)\n",
    "\n",
    "                    geemap.ee_export_image(ndvi, ndvi_output_path, region=jharkhand, scale=10, **export_options)\n",
    "                    geemap.ee_export_image(evi, evi_output_path, region=jharkhand, scale=30, **export_options)\n",
    "                    geemap.ee_export_image(ndwi, ndwi_output_path, region=jharkhand, scale=10, **export_options)\n",
    "\n",
    "                    break  # Exit the loop when an image is found for the current year and month\n",
    "\n",
    "        if not images_found:\n",
    "            # If no images are found for the current year, continue to the next year\n",
    "            print(f\"No images found for year {year}. Moving to the next year.\")\n",
    "\n",
    "# Example usage:\n",
    "start_year = 1984\n",
    "end_year = 2022\n",
    "feature_collection = ee.FeatureCollection(\"projects/webapp-385310/assets/Sonitpur-Udalguri\").geometry()\n",
    "output_dir = '/path/to/output/directory'\n",
    "cloudCover = 30\n",
    "\n",
    "# Export Landsat images, NDVI, EVI, and NDWI for each year, adding months gradually until a suitable image is found\n",
    "export_landsat_images(start_year, end_year, feature_collection, output_dir, cloudCover)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f4867b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ecf84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e905f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import os\n",
    "import time\n",
    "\n",
    "def export_landsat_images(start_year, end_year, feature_collection, output_folder, cloudCover):\n",
    "    ee.Initialize()\n",
    "\n",
    "    # Define the region of interest\n",
    "    jharkhand = feature_collection\n",
    "\n",
    "    # Loop through the years\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        images_found = False  # Flag to check if images are found for the current year\n",
    "\n",
    "        # Create a band mapping dictionary based on the Landsat sensor\n",
    "        band_mapping = {\n",
    "            'LT05': {'BLUE': 'B1', 'RED': 'B3', 'NIR': 'B4', 'SWIR': 'B5'},\n",
    "            'LE07': {'BLUE': 'B1', 'RED': 'B3', 'NIR': 'B4', 'SWIR': 'B5'},\n",
    "            'LC08': {'BLUE': 'B2', 'RED': 'B4', 'NIR': 'B5', 'SWIR': 'B6'},\n",
    "            'LC09': {'BLUE': 'B2', 'RED': 'B4', 'NIR': 'B5', 'SWIR': 'B6'}\n",
    "        }\n",
    "\n",
    "        # Get the Landsat sensor based on the year\n",
    "        landsat_sensor = None\n",
    "        if year < 1999:\n",
    "            landsat_sensor = 'LT05'\n",
    "        elif 1999 <= year < 2014:\n",
    "            landsat_sensor = 'LE07'\n",
    "        elif 2014 <= year < 2022:\n",
    "            landsat_sensor = 'LC08'\n",
    "        else:\n",
    "            landsat_sensor = 'LC09'\n",
    "\n",
    "        # Iterate through months from January to December\n",
    "        for month in range(1, 13):\n",
    "            # Set the start and end dates for the current month\n",
    "            start_date = f'{year}-{month:02d}-01'\n",
    "            end_date = f'{year}-{month:02d}-28'\n",
    "\n",
    "            # Filter Landsat collection for the specified year and month\n",
    "            landsat_collection = ee.ImageCollection(f\"LANDSAT/{landsat_sensor}/C02/T1_TOA\")\n",
    "\n",
    "            images = landsat_collection.filter(ee.Filter.lt('CLOUD_COVER', cloudCover)) \\\n",
    "                     .filter(ee.Filter.date(start_date, end_date)) \\\n",
    "                     .filterBounds(jharkhand)\n",
    "\n",
    "            # Check if images are found for the current month\n",
    "            if images.size().getInfo() > 0:\n",
    "                images_found = True\n",
    "\n",
    "                # Take the mean of the images for the specified period\n",
    "                image = images.mean()\n",
    "\n",
    "                # Define output filename for Landsat\n",
    "                landsat_filename = f'Landsat_{year}_{month:02d}.tif'\n",
    "                landsat_output_path = os.path.join(output_folder, 'Landsat', landsat_filename)\n",
    "\n",
    "                # Export each band of the Landsat image separately with export options\n",
    "                for band_name, band_id in band_mapping[landsat_sensor].items():\n",
    "                    band_image = image\n",
    "\n",
    "                    # Define output filename for the current band\n",
    "                    band_filename = f'Landsat_{year}_{month:02d}_{band_name}.tif'\n",
    "                    band_output_path = os.path.join(output_folder, 'Landsat', band_filename)\n",
    "\n",
    "                    # Set export options for CRS and maxPixels\n",
    "                    export_options = {\n",
    "                        'crs': 'EPSG:32644',  # Change to your desired CRS\n",
    "                        'maxPixels': 1e13  # Change to an appropriate value\n",
    "                    }\n",
    "\n",
    "                    # Export the current band to Google Drive with export_options\n",
    "                    export_task = ee.batch.Export.image.toDrive(\n",
    "                        image=band_image,\n",
    "                        description=f'Landsat {band_name} Export',\n",
    "                        folder=output_folder,\n",
    "                        fileNamePrefix=f'Landsat/{band_filename}',\n",
    "                        scale=30,\n",
    "                        region=jharkhand,\n",
    "                        **export_options  # Include export options\n",
    "                    )\n",
    "                    export_task.start()\n",
    "\n",
    "                    # Wait for export task to complete\n",
    "                    while export_task.active():\n",
    "                        print(f'Exporting {band_name}...')\n",
    "                        time.sleep(30)  # Wait for 30 seconds before checking again\n",
    "\n",
    "                print(f'Export completed for Landsat {year}_{month:02d}')\n",
    "\n",
    "                # Calculate NDVI, EVI, and NDWI\n",
    "                band_info = band_mapping[landsat_sensor]\n",
    "                ndvi = image.normalizedDifference([band_info['NIR'], band_info['RED']])\n",
    "                evi = image.expression(\n",
    "                    '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
    "                        'NIR': image.select(band_info['NIR']),\n",
    "                        'RED': image.select(band_info['RED']),\n",
    "                        'BLUE': image.select(band_info['BLUE'])\n",
    "                    })\n",
    "                ndwi = image.normalizedDifference([band_info['NIR'], band_info['SWIR']])\n",
    "\n",
    "                # Define output filenames for NDVI, EVI, and NDWI\n",
    "                ndvi_filename = f'Landsat_{year}_{month:02d}_NDVI.tif'\n",
    "                evi_filename = f'Landsat_{year}_{month:02d}_EVI.tif'\n",
    "                ndwi_filename = f'Landsat_{year}_{month:02d}_NDWI.tif'\n",
    "\n",
    "                ndvi_output_path = os.path.join(output_folder, 'NDVI', ndvi_filename)\n",
    "                evi_output_path = os.path.join(output_folder, 'EVI', evi_filename)\n",
    "                ndwi_output_path = os.path.join(output_folder, 'NDWI', ndwi_filename)\n",
    "\n",
    "                # Export NDVI, EVI, and NDWI to Google Drive with export options\n",
    "                export_ndvi_task = ee.batch.Export.image.toDrive(\n",
    "                    image=ndvi,\n",
    "                    description='NDVI Export',\n",
    "                    folder=output_folder,\n",
    "                    fileNamePrefix='NDVI/' + ndvi_filename,\n",
    "                    scale=30,\n",
    "                    region=jharkhand,\n",
    "                    **export_options  # Include export options\n",
    "                )\n",
    "                export_evi_task = ee.batch.Export.image.toDrive(\n",
    "                    image=evi,\n",
    "                    description='EVI Export',\n",
    "                    folder=output_folder,\n",
    "                    fileNamePrefix='EVI/' + evi_filename,\n",
    "                    scale=30,\n",
    "                    region=jharkhand,\n",
    "                    **export_options  # Include export options\n",
    "                )\n",
    "                export_ndwi_task = ee.batch.Export.image.toDrive(\n",
    "                    image=ndwi,\n",
    "                    description='NDWI Export',\n",
    "                    folder=output_folder,\n",
    "                    fileNamePrefix='NDWI/' + ndwi_filename,\n",
    "                    scale=30,\n",
    "                    region=jharkhand,\n",
    "                    **export_options  # Include export options\n",
    "                )\n",
    "\n",
    "                export_ndvi_task.start()\n",
    "                export_evi_task.start()\n",
    "                export_ndwi_task.start()\n",
    "\n",
    "                # Wait for export tasks to complete\n",
    "                while export_task.active() or export_ndvi_task.active() or export_evi_task.active() or export_ndwi_task.active():\n",
    "                    print('Exporting...')  # You can replace this with a more informative message\n",
    "                    time.sleep(30)  # Wait for 30 seconds before checking again\n",
    "\n",
    "                print(f'Export completed for Landsat {year}_{month:02d}')\n",
    "\n",
    "                break  # Exit the loop when an image is found for the current year\n",
    "\n",
    "        if not images_found:\n",
    "            print(f\"No images found for year {year}. Moving to the next year.\")\n",
    "\n",
    "# Example usage:\n",
    "start_year = 2021\n",
    "end_year = 2022\n",
    "feature_collection = ee.FeatureCollection(\"projects/webapp-385310/assets/Sonitpur-Udalguri\").geometry()\n",
    "output_folder = 'GEE_Exports'  # Replace with your Google Drive folder name\n",
    "cloudCover = 50\n",
    "\n",
    "# Export Landsat images, NDVI, EVI, and NDWI for each year, adding months gradually until December if necessary\n",
    "export_landsat_images(start_year, end_year, feature_collection, output_folder, cloudCover)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb77e433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910c5048",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589fbfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting BLUE...\n",
      "Exporting BLUE...\n",
      "Exporting BLUE...\n",
      "Exporting RED...\n",
      "Exporting RED...\n",
      "Exporting RED...\n",
      "Exporting NIR...\n",
      "Exporting NIR...\n",
      "Exporting NIR...\n",
      "Exporting NIR...\n",
      "Exporting SWIR...\n",
      "Exporting SWIR...\n",
      "Exporting SWIR...\n",
      "Exporting TIRS...\n",
      "Exporting TIRS...\n",
      "Exporting GREEN...\n",
      "Exporting GREEN...\n",
      "Export completed for Landsat 2018_01\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Export completed for Landsat 2018_01\n",
      "Exporting BLUE...\n",
      "Exporting BLUE...\n",
      "Exporting BLUE...\n",
      "Exporting RED...\n",
      "Exporting RED...\n",
      "Exporting RED...\n",
      "Exporting NIR...\n",
      "Exporting NIR...\n",
      "Exporting NIR...\n",
      "Exporting SWIR...\n",
      "Exporting SWIR...\n",
      "Exporting SWIR...\n",
      "Exporting TIRS...\n",
      "Exporting TIRS...\n",
      "Exporting TIRS...\n",
      "Exporting GREEN...\n",
      "Exporting GREEN...\n",
      "Exporting GREEN...\n",
      "Export completed for Landsat 2019_01\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Export completed for Landsat 2019_01\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import os\n",
    "import time\n",
    "\n",
    "def export_landsat_images(start_year, end_year, feature_collection, output_folder, cloudCover, pathNumber, rowNumber1,rowNumber2):\n",
    "    ee.Initialize()\n",
    "\n",
    "    # Define the region of interest\n",
    "    jharkhand = feature_collection\n",
    "\n",
    "    # Loop through the years\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        images_found = False  # Flag to check if images are found for the current year\n",
    "\n",
    "        # Create a band mapping dictionary based on the Landsat sensor\n",
    "        band_mapping = {\n",
    "            'LT05': {'BLUE': 'B1', 'RED': 'B3', 'NIR': 'B4', 'SWIR': 'B5','TIRS':'B6','GREEN':'B2'},\n",
    "            'LE07': {'BLUE': 'B1', 'RED': 'B3', 'NIR': 'B4', 'SWIR': 'B5','TIRS':'B6_VCID_2','GREEN':'B2'},\n",
    "            'LC08': {'BLUE': 'B2', 'RED': 'B4', 'NIR': 'B5', 'SWIR': 'B6','TIRS':'B10','GREEN':'B3'},\n",
    "            'LC09': {'BLUE': 'B2', 'RED': 'B4', 'NIR': 'B5', 'SWIR': 'B6','TIRS':'B10','GREEN':'B3'}\n",
    "        }\n",
    "\n",
    "        # Get the Landsat sensor based on the year\n",
    "        landsat_sensor = None\n",
    "        if year < 2000:\n",
    "            landsat_sensor = 'LT05'\n",
    "        elif 1999 <= year < 2014:\n",
    "            landsat_sensor = 'LE07'\n",
    "        elif 2014 <= year < 2022:\n",
    "            landsat_sensor = 'LC08'\n",
    "        else:\n",
    "            landsat_sensor = 'LC09'\n",
    "\n",
    "        # Iterate through months from January to December\n",
    "        for month in range(1, 13):\n",
    "            # Set the start and end dates for the current month\n",
    "            start_date = f'{year}-01-01'\n",
    "            end_date = f'{year}-12-28'\n",
    "\n",
    "            # Filter Landsat collection for the specified year and month\n",
    "            landsat_collection = ee.ImageCollection(f\"LANDSAT/{landsat_sensor}/C02/T1_TOA\")\n",
    "\n",
    "            images_1 = landsat_collection.filter(ee.Filter.lt('CLOUD_COVER', cloudCover)) \\\n",
    "                     .filter(ee.Filter.date(start_date, end_date)) \\\n",
    "                     .filterBounds(jharkhand)\\\n",
    "                     .filter(ee.Filter.eq('WRS_ROW',rowNumber1))\\\n",
    "                     .filter(ee.Filter.eq('WRS_ROW',rowNumber1))\\\n",
    "                     .filter(ee.Filter.eq('WRS_PATH',pathNumber))\\\n",
    "                     .first()\n",
    "            # Get the date of the first image in images_1\n",
    "            first_image_date = ee.Image(images_1).date()\n",
    "            \n",
    "\n",
    "            images_2 = landsat_collection.filter(ee.Filter.lt('CLOUD_COVER', cloudCover)) \\\n",
    "                     .filter(ee.Filter.date(first_image_date, first_image_date.advance(1, 'day'))) \\\n",
    "                     .filterBounds(jharkhand)\\\n",
    "                     .filter(ee.Filter.eq('WRS_ROW',rowNumber2))\\\n",
    "                     .filter(ee.Filter.eq('WRS_ROW',rowNumber2))\\\n",
    "                     .filter(ee.Filter.eq('WRS_PATH',pathNumber))\\\n",
    "                     .first()\n",
    "                \n",
    "            #images = images_1.merge(images_2)\n",
    "            images = ee.ImageCollection([images_1, images_2])\n",
    "                \n",
    "            \n",
    "\n",
    "            # Check if images are found for the current month\n",
    "            if images.size().getInfo() > 0:\n",
    "                images_found = True\n",
    "\n",
    "                # Take the mean of the images for the specified period\n",
    "                image = images.mosaic()\n",
    "\n",
    "                # Define output filename for Landsat\n",
    "                landsat_filename = f'Landsat_{year}_{month:02d}.tif'\n",
    "                landsat_output_path = os.path.join(output_folder, 'Landsat', landsat_filename)\n",
    "\n",
    "                # Export each band of the Landsat image separately with export options\n",
    "                for band_name, band_id in band_mapping[landsat_sensor].items():\n",
    "                    band_image = image.select(band_id)\n",
    "\n",
    "                    # Define output filename for the current band\n",
    "                    band_filename = f'Landsat_{year}_{month:02d}_{band_name}.tif'\n",
    "                    band_output_path = os.path.join(output_folder, 'Landsat', band_filename)\n",
    "\n",
    "                    # Set export options for CRS and maxPixels\n",
    "                    export_options = {\n",
    "                        'crs': 'EPSG:32644',  # Change to your desired CRS\n",
    "                        'maxPixels': 1e13  # Change to an appropriate value\n",
    "                    }\n",
    "\n",
    "                    # Export the current band to Google Drive with export_options\n",
    "                    export_task = ee.batch.Export.image.toDrive(\n",
    "                        image=band_image,\n",
    "                        description=f'Landsat {band_name} Export',\n",
    "                        folder=output_folder,\n",
    "                        fileNamePrefix=f'Landsat/{band_filename}',\n",
    "                        scale=30,\n",
    "                        region=jharkhand,\n",
    "                        **export_options  # Include export options\n",
    "                    )\n",
    "                    export_task.start()\n",
    "\n",
    "                    # Wait for export task to complete\n",
    "                    while export_task.active():\n",
    "                        print(f'Exporting {band_name}...')\n",
    "                        time.sleep(30)  # Wait for 30 seconds before checking again\n",
    "\n",
    "                print(f'Export completed for Landsat {year}_{month:02d}')\n",
    "\n",
    "                # Calculate NDVI, EVI, and NDWI\n",
    "                band_info = band_mapping[landsat_sensor]\n",
    "                ndvi = image.normalizedDifference([band_info['NIR'], band_info['RED']])\n",
    "                evi = image.expression(\n",
    "                    '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))', {\n",
    "                        'NIR': image.select(band_info['NIR']),\n",
    "                        'RED': image.select(band_info['RED']),\n",
    "                        'BLUE': image.select(band_info['BLUE'])\n",
    "                    })\n",
    "                ndwi = image.normalizedDifference([band_info['NIR'], band_info['SWIR']])\n",
    "\n",
    "                # Define output filenames for NDVI, EVI, and NDWI\n",
    "                ndvi_filename = f'Landsat_{year}_{month:02d}_NDVI.tif'\n",
    "                evi_filename = f'Landsat_{year}_{month:02d}_EVI.tif'\n",
    "                ndwi_filename = f'Landsat_{year}_{month:02d}_NDWI.tif'\n",
    "\n",
    "                ndvi_output_path = os.path.join(output_folder, 'NDVI', ndvi_filename)\n",
    "                evi_output_path = os.path.join(output_folder, 'EVI', evi_filename)\n",
    "                ndwi_output_path = os.path.join(output_folder, 'NDWI', ndwi_filename)\n",
    "\n",
    "                # Export NDVI, EVI, and NDWI to Google Drive with export options\n",
    "                export_ndvi_task = ee.batch.Export.image.toDrive(\n",
    "                    image=ndvi,\n",
    "                    description='NDVI Export',\n",
    "                    folder=output_folder,\n",
    "                    fileNamePrefix='NDVI/' + ndvi_filename,\n",
    "                    scale=30,\n",
    "                    region=jharkhand,\n",
    "                    **export_options  # Include export options\n",
    "                )\n",
    "                export_evi_task = ee.batch.Export.image.toDrive(\n",
    "                    image=evi,\n",
    "                    description='EVI Export',\n",
    "                    folder=output_folder,\n",
    "                    fileNamePrefix='EVI/' + evi_filename,\n",
    "                    scale=30,\n",
    "                    region=jharkhand,\n",
    "                    **export_options  # Include export options\n",
    "                )\n",
    "                export_ndwi_task = ee.batch.Export.image.toDrive(\n",
    "                    image=ndwi,\n",
    "                    description='NDWI Export',\n",
    "                    folder=output_folder,\n",
    "                    fileNamePrefix='NDWI/' + ndwi_filename,\n",
    "                    scale=30,\n",
    "                    region=jharkhand,\n",
    "                    **export_options  # Include export options\n",
    "                )\n",
    "\n",
    "                export_ndvi_task.start()\n",
    "                export_evi_task.start()\n",
    "                export_ndwi_task.start()\n",
    "\n",
    "                # Wait for export tasks to complete\n",
    "                while export_task.active() or export_ndvi_task.active() or export_evi_task.active() or export_ndwi_task.active():\n",
    "                    print('Exporting...')  # You can replace this with a more informative message\n",
    "                    time.sleep(30)  # Wait for 30 seconds before checking again\n",
    "\n",
    "                print(f'Export completed for Landsat {year}_{month:02d}')\n",
    "\n",
    "                break  # Exit the loop when an image is found for the current year\n",
    "\n",
    "        if not images_found:\n",
    "            print(f\"No images found for year {year}. Moving to the next year.\")\n",
    "\n",
    "# Example usage:\n",
    "start_year = 2018\n",
    "end_year = 2019\n",
    "feature_collection = ee.FeatureCollection(\"projects/webapp-385310/assets/studyarea_dl\").geometry()\n",
    "output_folder = 'GEE_Exports'  # Replace with your Google Drive folder name\n",
    "cloudCover = 20\n",
    "pathNumber = 136\n",
    "rowNumber1 = 41\n",
    "rowNumber2=42\n",
    "\n",
    "\n",
    "# Export Landsat images for each year, mosaic them and export the mosaic\n",
    "export_landsat_images(start_year, end_year, feature_collection, output_folder, cloudCover, pathNumber, rowNumber1,rowNumber2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef364ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e89b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dafda6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Image', 'bands': [{'id': 'B5_asm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_contrast', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_corr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_var', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_idm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_savg', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_svar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_sent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_ent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dvar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr1', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr2', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_maxcorr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_diss', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_inertia', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_shade', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_prom', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}]}\n",
      "NaN value found in year 2016, month 1. Adding the next month and taking the mean.\n",
      "Exporting GLCM texture properties for 2016 to Google Drive...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Export completed for GLCM texture properties for 2016\n",
      "{'type': 'Image', 'bands': [{'id': 'B5_asm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_contrast', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_corr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_var', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_idm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_savg', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_svar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_sent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_ent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dvar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr1', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr2', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_maxcorr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_diss', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_inertia', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_shade', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_prom', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}]}\n",
      "NaN value found in year 2017, month 1. Adding the next month and taking the mean.\n",
      "Exporting GLCM texture properties for 2017 to Google Drive...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Export completed for GLCM texture properties for 2017\n",
      "{'type': 'Image', 'bands': [{'id': 'B5_asm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_contrast', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_corr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_var', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_idm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_savg', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_svar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_sent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_ent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dvar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr1', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr2', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_maxcorr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_diss', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_inertia', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_shade', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_prom', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}]}\n",
      "NaN value found in year 2018, month 1. Adding the next month and taking the mean.\n",
      "Exporting GLCM texture properties for 2018 to Google Drive...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Export completed for GLCM texture properties for 2018\n",
      "{'type': 'Image', 'bands': [{'id': 'B5_asm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_contrast', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_corr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_var', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_idm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_savg', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_svar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_sent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_ent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dvar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr1', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr2', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_maxcorr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_diss', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_inertia', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_shade', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_prom', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}]}\n",
      "NaN value found in year 2019, month 1. Adding the next month and taking the mean.\n",
      "Exporting GLCM texture properties for 2019 to Google Drive...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Export completed for GLCM texture properties for 2019\n",
      "{'type': 'Image', 'bands': [{'id': 'B5_asm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_contrast', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_corr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_var', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_idm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_savg', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_svar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_sent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_ent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dvar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr1', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr2', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_maxcorr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_diss', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_inertia', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_shade', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_prom', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}]}\n",
      "NaN value found in year 2020, month 1. Adding the next month and taking the mean.\n",
      "Exporting GLCM texture properties for 2020 to Google Drive...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Export completed for GLCM texture properties for 2020\n",
      "{'type': 'Image', 'bands': [{'id': 'B5_asm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_contrast', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_corr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_var', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_idm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_savg', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_svar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_sent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_ent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dvar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr1', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr2', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_maxcorr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_diss', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_inertia', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_shade', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_prom', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}]}\n",
      "NaN value found in year 2021, month 1. Adding the next month and taking the mean.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting GLCM texture properties for 2021 to Google Drive...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Export completed for GLCM texture properties for 2021\n",
      "{'type': 'Image', 'bands': [{'id': 'B5_asm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_contrast', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_corr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_var', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_idm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_savg', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_svar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_sent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_ent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dvar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr1', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr2', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_maxcorr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_diss', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_inertia', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_shade', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_prom', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}]}\n",
      "NaN value found in year 2022, month 1. Adding the next month and taking the mean.\n",
      "Exporting GLCM texture properties for 2022 to Google Drive...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Export completed for GLCM texture properties for 2022\n",
      "{'type': 'Image', 'bands': [{'id': 'B5_asm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_contrast', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_corr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_var', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_idm', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_savg', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_svar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_sent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_ent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dvar', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_dent', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr1', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_imcorr2', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_maxcorr', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_diss', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_inertia', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_shade', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}, {'id': 'B5_prom', 'data_type': {'type': 'PixelType', 'precision': 'double'}, 'crs': 'EPSG:4326', 'crs_transform': [1, 0, 0, 0, 1, 0]}]}\n",
      "NaN value found in year 2023, month 1. Adding the next month and taking the mean.\n",
      "Exporting GLCM texture properties for 2023 to Google Drive...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Exporting...\n",
      "Export completed for GLCM texture properties for 2023\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Initialize Earth Engine\n",
    "ee.Initialize()\n",
    "\n",
    "# Define the region of interest (ROI) as a geometry\n",
    "table = ee.FeatureCollection(\"projects/webapp-385310/assets/studyarea_dl\").geometry()\n",
    "\n",
    "# Define the NIR band name for different Landsat sensors\n",
    "def get_nir_band(landsat_sensor):\n",
    "    if landsat_sensor in ['LT05', 'LE07']:\n",
    "        return 'B4'\n",
    "    elif landsat_sensor in ['LC08', 'LC09']:\n",
    "        return 'B5'\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported Landsat sensor: {landsat_sensor}\")\n",
    "\n",
    "# Loop through the years from 1984 to 2023\n",
    "for year in range(2016, 2024):\n",
    "    images_found = False  # Flag to check if images are found for the current year\n",
    "\n",
    "    # Get the Landsat sensor based on the year\n",
    "    landsat_sensor = None\n",
    "    if year < 2000:\n",
    "        landsat_sensor = 'LT05'\n",
    "    elif 1999 <= year < 2014:\n",
    "        landsat_sensor = 'LE07'\n",
    "    elif 2014 <= year < 2022:\n",
    "        landsat_sensor = 'LC08'\n",
    "    else:\n",
    "        landsat_sensor = 'LC09'\n",
    "\n",
    "    # Initialize GLCM variables for each texture property\n",
    "    glcm_mean_contrast = None\n",
    "    glcm_mean_correlation = None\n",
    "    glcm_mean_dissimilarity = None\n",
    "    glcm_mean_energy = None\n",
    "    glcm_mean_entropy = None\n",
    "    glcm_count = 0\n",
    "\n",
    "    # Initialize a flag to check if any NaN values are found\n",
    "    nan_found = False\n",
    "\n",
    "    # Iterate through months from January to December\n",
    "    for month in range(1, 13):\n",
    "        # Check if NaN values are found in the images\n",
    "        if nan_found:\n",
    "            print(f\"NaN value found in year {year}, month {month}. Adding the next month and taking the mean.\")\n",
    "        else:\n",
    "            # Set the start and end dates for the current month\n",
    "            start_date = f'{year}-01-01'\n",
    "            end_date = f'{year}-12-28'\n",
    "\n",
    "            # Filter Landsat collection for the specified year and month\n",
    "            landsat_collection = ee.ImageCollection(f\"LANDSAT/{landsat_sensor}/C02/T1_TOA\")\n",
    "\n",
    "            \n",
    "            images_1 = landsat_collection.filter(ee.Filter.lt('CLOUD_COVER', cloudCover)) \\\n",
    "                     .filter(ee.Filter.date(start_date, end_date)) \\\n",
    "                     .filterBounds(table)\\\n",
    "                     .filter(ee.Filter.eq('WRS_ROW',41))\\\n",
    "                     .filter(ee.Filter.eq('WRS_ROW',41))\\\n",
    "                     .filter(ee.Filter.eq('WRS_PATH',136))\\\n",
    "                     .first()\n",
    "            # Get the date of the first image in images_1\n",
    "            first_image_date = ee.Image(images_1).date()\n",
    "            \n",
    "\n",
    "            images_2 = landsat_collection.filter(ee.Filter.lt('CLOUD_COVER', cloudCover)) \\\n",
    "                     .filter(ee.Filter.date(first_image_date, first_image_date.advance(1, 'day'))) \\\n",
    "                     .filterBounds(table)\\\n",
    "                     .filter(ee.Filter.eq('WRS_ROW',42))\\\n",
    "                     .filter(ee.Filter.eq('WRS_ROW',42))\\\n",
    "                     .filter(ee.Filter.eq('WRS_PATH',136))\\\n",
    "                     .first()\n",
    "                \n",
    "            #images = images_1.merge(images_2)\n",
    "            images = ee.ImageCollection([images_1, images_2])\n",
    "                \n",
    "            \n",
    "\n",
    "            # Check if images are found for the current month\n",
    "            if images.size().getInfo() > 0:\n",
    "                images_found = True\n",
    "\n",
    "                # Take the mean of the images for the specified period\n",
    "                image = images.mosaic()\n",
    "\n",
    "\n",
    "                # Select NIR band for GLCM\n",
    "                nir_band = get_nir_band(landsat_sensor)\n",
    "                nir_image = image.select(nir_band)\n",
    "\n",
    "                # Convert NIR band to 32-bit integer\n",
    "                nir_image_int = nir_image.multiply(10000).toInt32()\n",
    "\n",
    "                # Calculate GLCM texture properties\n",
    "                texture = nir_image_int.glcmTexture()\n",
    "                \n",
    "                print(texture.getInfo())\n",
    "\n",
    "                # Select GLCM bands\n",
    "                contrast = texture.select(get_nir_band(landsat_sensor)+'_contrast')\n",
    "                correlation = texture.select(get_nir_band(landsat_sensor)+'_corr')\n",
    "                dissimilarity = texture.select(get_nir_band(landsat_sensor)+'_diss')\n",
    "                energy = texture.select(get_nir_band(landsat_sensor)+'_energy')\n",
    "                entropy = texture.select(get_nir_band(landsat_sensor)+'_entropy')\n",
    "\n",
    "                # Update GLCM means for each texture property\n",
    "                if glcm_mean_contrast is None:\n",
    "                    glcm_mean_contrast = contrast\n",
    "                    glcm_mean_correlation = correlation\n",
    "                    glcm_mean_dissimilarity = dissimilarity\n",
    "                    glcm_mean_energy = energy\n",
    "                    glcm_mean_entropy = entropy\n",
    "                else:\n",
    "                    glcm_mean_contrast = glcm_mean_contrast.add(contrast)\n",
    "                    glcm_mean_correlation = glcm_mean_correlation.add(correlation)\n",
    "                    glcm_mean_dissimilarity = glcm_mean_dissimilarity.add(dissimilarity)\n",
    "                    glcm_mean_energy = glcm_mean_energy.add(energy)\n",
    "                    glcm_mean_entropy = glcm_mean_entropy.add(entropy)\n",
    "                \n",
    "                glcm_count += 1\n",
    "\n",
    "                # Check for NaN values in the contrast image\n",
    "                if contrast.reduceRegion(reducer=ee.Reducer.anyNonZero(), geometry=table, scale=30).getInfo():\n",
    "                    nan_found = True\n",
    "                    print(f\"NaN value found in year {year}, month {month}. Adding the next month and taking the mean.\")\n",
    "                    break  # Exit the loop for the current year and month\n",
    "\n",
    "    # Calculate the mean of GLCM texture properties across all valid months\n",
    "    if glcm_mean_contrast is not None and glcm_count > 0:\n",
    "        glcm_mean_contrast = glcm_mean_contrast.divide(glcm_count)\n",
    "        glcm_mean_correlation = glcm_mean_correlation.divide(glcm_count)\n",
    "        glcm_mean_dissimilarity = glcm_mean_dissimilarity.divide(glcm_count)\n",
    "        glcm_mean_energy = glcm_mean_energy.divide(glcm_count)\n",
    "        glcm_mean_entropy = glcm_mean_entropy.divide(glcm_count)\n",
    "\n",
    "        # Clip the GLCM images to the ROI\n",
    "        glcm_mean_contrast = glcm_mean_contrast.clip(table)\n",
    "        glcm_mean_correlation = glcm_mean_correlation.clip(table)\n",
    "        glcm_mean_dissimilarity = glcm_mean_dissimilarity.clip(table)\n",
    "        glcm_mean_energy = glcm_mean_energy.clip(table)\n",
    "        glcm_mean_entropy = glcm_mean_entropy.clip(table)\n",
    "\n",
    "        # Define the output folder\n",
    "        output_folder = 'GEEexport'\n",
    "\n",
    "        # Define output filenames for GLCM texture properties\n",
    "        glcm_contrast_filename = f'GLCM_contrast_{year}.tif'\n",
    "        glcm_correlation_filename = f'GLCM_correlation_{year}.tif'\n",
    "        glcm_dissimilarity_filename = f'GLCM_dissimilarity_{year}.tif'\n",
    "        glcm_energy_filename = f'GLCM_energy_{year}.tif'\n",
    "        glcm_entropy_filename = f'GLCM_entropy_{year}.tif'\n",
    "\n",
    "        # Export options\n",
    "        export_options = {\n",
    "            'scale': 30,\n",
    "            'region': table,\n",
    "            'crs': 'EPSG:32644',  # Change to your desired CRS\n",
    "            'maxPixels': 1e13  # Change to an appropriate value\n",
    "        }\n",
    "\n",
    "        # Export GLCM texture properties to Google Drive with export options\n",
    "        export_glcm_contrast_task = ee.batch.Export.image.toDrive(\n",
    "            image=glcm_mean_contrast,\n",
    "            description='GLCM Contrast Export',\n",
    "            folder=output_folder,\n",
    "            fileNamePrefix=glcm_contrast_filename,\n",
    "            **export_options  # Include export options\n",
    "        )\n",
    "\n",
    "        export_glcm_correlation_task = ee.batch.Export.image.toDrive(\n",
    "            image=glcm_mean_correlation,\n",
    "            description='GLCM Correlation Export',\n",
    "            folder=output_folder,\n",
    "            fileNamePrefix=glcm_correlation_filename,\n",
    "            **export_options  # Include export options\n",
    "        )\n",
    "\n",
    "        export_glcm_dissimilarity_task = ee.batch.Export.image.toDrive(\n",
    "            image=glcm_mean_dissimilarity,\n",
    "            description='GLCM Dissimilarity Export',\n",
    "            folder=output_folder,\n",
    "            fileNamePrefix=glcm_dissimilarity_filename,\n",
    "            **export_options  # Include export options\n",
    "        )\n",
    "\n",
    "        export_glcm_energy_task = ee.batch.Export.image.toDrive(\n",
    "            image=glcm_mean_energy,\n",
    "            description='GLCM Energy Export',\n",
    "            folder=output_folder,\n",
    "            fileNamePrefix=glcm_energy_filename,\n",
    "            **export_options  # Include export options\n",
    "        )\n",
    "\n",
    "        export_glcm_entropy_task = ee.batch.Export.image.toDrive(\n",
    "            image=glcm_mean_entropy,\n",
    "            description='GLCM Entropy Export',\n",
    "            folder=output_folder,\n",
    "            fileNamePrefix=glcm_entropy_filename,\n",
    "            **export_options  # Include export options\n",
    "        )\n",
    "\n",
    "        # Start export tasks\n",
    "        export_glcm_contrast_task.start()\n",
    "        export_glcm_correlation_task.start()\n",
    "        export_glcm_dissimilarity_task.start()\n",
    "        export_glcm_energy_task.start()\n",
    "        export_glcm_entropy_task.start()\n",
    "\n",
    "        print(f'Exporting GLCM texture properties for {year} to Google Drive...')\n",
    "\n",
    "        # Wait for export tasks to complete\n",
    "        while (export_glcm_contrast_task.active() or export_glcm_correlation_task.active()\n",
    "               or export_glcm_dissimilarity_task.active() or export_glcm_energy_task.active()\n",
    "               or export_glcm_entropy_task.active()):\n",
    "            print('Exporting...')  # You can replace this with a more informative message\n",
    "            time.sleep(30)  # Wait for 30 seconds before checking again\n",
    "\n",
    "        print(f'Export completed for GLCM texture properties for {year}')\n",
    "    elif not images_found:\n",
    "        print(f\"No images found for year {year}. Moving to the next year.\")\n",
    "\n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
